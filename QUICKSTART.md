# CAVE on GCP – Quickstart

This guide boots a CAVE environment using Terragrunt and Helmfile.


In contrast to MIGRATION.md this will assume you do not have any functioning clusters, and want to spin up all infrastructure from scratch.  At present, this guide is somewhat theoretical in that we have only migrated from an existing systems, so feedback on this document in the form of issues or pull requests are  highly welcome.

At a glance:
- Terragrunt + Terraform: provisions everything outside Kubernetes (SQL, Redis, networks, DNS, Pub/Sub, buckets, service accounts, IAM).
- Helmfile + Helm: deploys CAVE apps into Kubernetes using values generated by the Terraform modules.
- Helm charts live in the companion repo: https://github.com/CAVEconnectome/cave-helm-charts

## Prerequisites
- macOS with Homebrew
- Install tools:
  - `brew install --cask google-cloud-sdk`
  - `brew install terraform terragrunt kubectl helm helmfile jq direnv sops gitleaks`
- Authenticate:
  - `gcloud auth login`
  - `gcloud auth application-default login`
  - `gcloud config set project <PROJECT_ID>`

## Enable APIs
```
gcloud services enable \
  compute.googleapis.com container.googleapis.com dns.googleapis.com \
  redis.googleapis.com sqladmin.googleapis.com secretmanager.googleapis.com \
  iam.googleapis.com cloudresourcemanager.googleapis.com
```

## Create Terraform state bucket
```
gsutil mb -l us gs://<STATE_BUCKET>
```

## Create DB credentials secret
```
printf '%s' '{"username":"postgres","password":"<strong-secret>"}' \
 | gcloud secrets create <ENV>-postgres-credentials --data-file=-
```

## Environment repository
We reccomend that you setup a seperate repository/folder to store all your environment configurations. So make a new folder that you will store and track these files. 

You can see an example repository at https://www.github.com/CAVEconnectome/terraform-cave-private which is used to manage several cave deployments (3 global, and 6 local clusters).

copy the example-global-config.yaml and example-local-config.yaml into this folder on your 
## Generate a starter global environnent with CookieCutter

We reccomend that you setup a seperate repository to store all your environment configurations. So make a new folder that you will store and track these files. 

## Generate a starter local environment with Cookiecutter

We reccomend that you setup a seperate repository to store all your environment configurations. So make a new folder that you will store and track these files. 

copy an example cookiecutter template file into that directory (we will refer to this AS ENVIRONMENTS_REPO) and rename it to something (we will call it CC_TEMPLATE.yaml)

install cookiecutter (for example)
```
pipx install cookiecutter  # or pip install --user cookiecutter
```


cd into ENVIRONMENTS_REPO

```
cookiecutter terraform-google-cave/cookiecutter_templates/terragrunt-env


cookiecutter terraform-google-cave/cookiecutter_templates/terragrunt-env
```
Answer prompts: repo_name, org, environment, project_id, region, zone, etc.



## Provision
```
cd <repo_name>/environments/<org>/static
terragrunt init && terragrunt apply

cd ../<cluster_prefix>
terragrunt init && terragrunt apply
```

## Deploy apps with Helmfile
- Install the Helm Diff plugin (Helmfile uses `helm diff` for planning):
  - `/opt/homebrew/bin/helm plugin install https://github.com/databus23/helm-diff`
  - Verify: `/opt/homebrew/bin/helm plugin list` (should list `diff`)
  - If already installed: `/opt/homebrew/bin/helm plugin update diff`

```
cd <repo_name>/environments/<org>/<cluster_prefix>/helmfile
cp helmfile.yaml.example helmfile.yaml
./configure.sh
# Edit helmfile.yaml and create overrides (e.g., materialize.yaml) as needed
helmfile apply
# Tip: If you cannot install the plugin, use --skip-diff as a temporary workaround
# helmfile apply --skip-diff
```



## How the pieces fit (modules and environments)

For each cluster, there are two Terraform module layers coordinated by Terragrunt:
- infrastructure: long-lived shared services (Cloud SQL, Redis, VPC, DNS, buckets, Pub/Sub, etc.). Persist across cluster re-creations.
- cluster: the GKE cluster and templated Helm values derived from infra outputs. This layer prepares the in-cluster prerequisites and writes defaults consumed by Helmfile.

In CAVE, there are both local and global clusters, so there will be four modules overall: local_infrastructure, local_cluster, global_infrastructure, global_cluster. Terragrunt shares common inputs (project_id, region, cluster_prefix) across them and manages ordering.

The Terraform modules render values files and templates that Helmfile consumes (for example, queue/exchange names, Bigtable instance, Redis host, domainName, Workload Identity SAs). This wiring lets the Helm charts connect to the external infrastructure.

Helm charts are developed for Google Cloud (GKE) and may need adjustments on other Kubernetes platforms (e.g., scalers, IAM annotations, ingress classes). See the cave-helm-charts README for details.

## Security checklist for making repos public
- Scan for secrets: `gitleaks detect -v`
- Ensure no tfstate files are committed
- Use Secret Manager or SOPS for any app secrets
- Consider exposing project IDs acceptable

## Troubleshooting
- Clear caches if provider/schema errors:
  - `rm -rf .terragrunt-cache` and re-run `terragrunt init -upgrade`
- Verify kube credentials: `kubectl get ns`
- Check Helm repos: `helm repo add jetstack https://charts.jetstack.io && helm repo update`

## New to Terraform/Terragrunt/Helm?
- Terraform: https://developer.hashicorp.com/terraform/docs
- Terragrunt (wrapper for DRY Terraform): https://terragrunt.gruntwork.io/docs/
- Helm (Kubernetes package manager): https://helm.sh/docs/
- Helmfile (stateful Helm deployments): https://helmfile.readthedocs.io/

This repo’s Cookiecutter template scaffolds a starter environment with sensible defaults and scripts to import existing resources into Terraform state if you are migrating from legacy setups.
