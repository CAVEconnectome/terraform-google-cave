# {{ cookiecutter.repo_name }}

Starter Terragrunt environment for CAVE on GCP.

## Layout
- environments/{{ cookiecutter.org }}/root.hcl
- environments/{{ cookiecutter.org }}/static/terragrunt.hcl  # shared infra (VPC, SQL, DNS, Redis)
- environments/{{ cookiecutter.org }}/{{ cookiecutter.environment }}/terragrunt.hcl  # cluster
- environments/{{ cookiecutter.org }}/scripts/terragrunt_import_sql.sh
- environments/{{ cookiecutter.org }}/{{ cookiecutter.environment }}/helmfile/  # generated by Terraform

Notes:
- "environment" (e.g., api, staging, prod) is the env folder name.
- cluster_name controls the cluster_prefix only; it does not create directories.
- Helm values use defaults+overrides: *.defaults.yaml are generated, user *.yaml overrides are optional.

How this works end-to-end:
- Terragrunt orchestrates Terraform to create and configure infrastructure outside Kubernetes (Cloud SQL, Redis, networks, DNS, Pub/Sub, buckets, Workload Identity/IAM).
- The Terraform modules write Helm values and defaults that capture those outputs so apps can connect.
- Helmfile deploys apps using the cave-helm-charts repository and the generated values.

Helm charts repo: https://github.com/CAVEconnectome/cave-helm-charts
Portability note: charts target Google Cloud (GKE) and may need adjustments on other Kubernetes platforms (scalers, IAM annotations, ingress).

## Variables
- repo_name: Name of the repository/folder that will be created for your environment repo. This does not affect resource names, only your local/git layout.
- org: Top-level folder name under environments/. Also used in the Terraform state prefix (gs://<state-bucket>/<org>/...). Choose something stable like your team or tenant name.
- environment: Logical environment name (e.g., api, staging, prod). Used by Terraform modules and for Secret Manager naming (<environment>-postgres-credentials). Also becomes the cluster folder path under environments/<org>/.
- cluster_name: Short identifier for this cluster (e.g., v5). Passed to the cluster module as cluster_prefix and used to form DNS entries (e.g., <cluster_name>.<domain_name>). It does not create a new directory; it scopes names and DNS.
- project_id: GCP project ID where resources are created and where Helmfile resolves secrets (ref+gcpsecrets://<project_id>/...).
- region: GCP region for regional resources (e.g., us-west1). Used by Terraform for GKE/Redis/Cloud SQL and rendered into Helm values (cluster.googleRegion).
- zone: GCP zone (e.g., us-west1-b). Used in the kubeContext string in cluster.yaml and rendered as cluster.googleZone. For regional clusters, leave as a zone in the same region (used for context formatting).
- owner: Arbitrary label used in naming and tagging resources (e.g., owner-environment in Redis name). Helpful for cost filtering; choose a short team identifier.
- sql_instance_name: Name of the existing or to-be-created Cloud SQL Postgres instance. Rendered into Helm defaults so apps can connect.
- dns_zone: Name of the Cloud DNS managed zone (e.g., em). Terraform uses this to create DNS records for the cluster.
- domain_name: Base domain served by the DNS zone (e.g., em.brain.example.org). Used to construct app hostnames and rendered into Helm values (cluster.domainName).
- letsencrypt_email: Email used by cert-manager’s ACME issuer for certificate management. Terraform uses this during cluster bootstrap.
- state_bucket: GCS bucket name for Terraform/Terragrunt state. Also used to point Helmfile to the static module’s tfstate (gs://<state_bucket>/<org>/static/terraform.tfstate) so it can resolve outputs like sql_instance_name.
- vpc_name_override: Optional. If you already have a VPC, set its name here to reuse it instead of letting Terraform create one. This affects import flows and naming.
- pcg_redis_name_override: Optional. Override the default Redis instance name if reusing an existing Memorystore instance.
- docker_registry: Container registry for image references in Helm values (cluster.dockerRegistry). Defaults to docker.io/caveconnectome; change if you mirror images.
- bigtable_google_project: Optional. If your Bigtable for PyChunkedGraph lives in another project, set that project ID. Rendered as cluster.dataProjectName in pychunkedgraph defaults; otherwise falls back to project_id.
- skeleton_cache_cloudpath: Optional. A gs:// path where Skeleton Cache files are written (e.g., gs://my-bucket/pcg_skeletons). If set in the static (infrastructure) layer, Terraform will import/manage the bucket, grant the SkeletonService SA permissions in the cluster layer, and pass the full path to the Helm chart. If omitted, Terraform creates a deterministic shared bucket named like owner-environment-skeleton-cache and uses gs://<bucket>.
- bigtable_instance_name: Bigtable instance name used by PyChunkedGraph (pychunkedgraph.defaults.yaml). Defaults to pychunkedgraph.
- cluster_global_server: Optional. A global server/base URL some charts reference (cluster.globalServer). The generated cluster.yaml leaves this empty; set it in a Helmfile override if you need it.
- datastack_name: defaults to v1dd.  This is the name of your first datastack (see and the template will 

## creating a materializaiton schedule
This template makes an example schedules.py file in the helmfile directory with your Celery beat schedule.  It can be customized to add more datastacks, or change the datastacks, the timing, or the frequency and expiration of materialization versions. 

The template will add a file for user customized materialize.yaml file for you to add config settings to.

```
materialize:
  schedules: "ref+file://schedules.py"
```


## Usage
- Set your state bucket in environments/{{ cookiecutter.org }}/root.hcl (bucket and helm_terraform_state_url).
- Provision infra:
  - cd environments/{{ cookiecutter.org }}/static && terragrunt init && terragrunt apply
- Provision cluster:
  - cd ../{{ cookiecutter.environment }} && terragrunt init && terragrunt apply
- Get kube creds, then deploy apps:
  - cd helmfile && cp helmfile.yaml.example helmfile.yaml && helmfile apply

Follow QUICKSTART in the root repo for full steps.

## Configure kube and Helm for this cluster
From environments/{{ cookiecutter.org }}/{{ cookiecutter.environment }}/helmfile:

```
./configure.sh
helmfile apply
```

The script:
- Sets gcloud project (from Terraform)
- Fetches GKE credentials (uses Terraform-provided region/zone; falls back from region to zone automatically)
- Ensures helm-diff plugin is installed
- Switches kubectl to the correct kubeContext (from Terraform)

## Optional: Skeleton Cache cloud path (gs://)

You can optionally set a single gs:// path to control where Skeleton Cache files go. This improves UX: one value informs bucket import/creation, IAM, and Helm config.

- Where to set: environments/{{ cookiecutter.org }}/static/terragrunt.hcl (shared infra layer)
- What to set: inputs.skeleton_cache_cloudpath = "gs://<bucket>/<optional/prefix>"

Example (commented placeholder to keep defaults unless you opt in):

```
# environments/{{ cookiecutter.org }}/static/terragrunt.hcl
terraform {
  source = "../../../../terraform-google-cave/modules/local_infrastructure"
}

include "root" {
  path = find_in_parent_folders("root.hcl")
}

# Optional: reuse an existing bucket/prefix for Skeleton Cache
# inputs = {
#   skeleton_cache_cloudpath = "gs://my-existing-bucket/pcg_skeletons"
# }
```

How it works under the hood:
- Infra parses the bucket from the gs:// path, imports it if it already exists (via the included import script), or creates a default bucket if you leave it unset.
- Cluster parses the same bucket to grant the SkeletonService service account storage permissions.
- Helm gets the full path and sets SKELETON_CACHE_BUCKET accordingly.
